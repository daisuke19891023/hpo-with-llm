# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This project uses Python 3.13+ and is built with the following technology stack:

-   **Web Framework**: FastAPI (https://fastapi.tiangolo.com/)
-   **Testing Framework**: pytest (https://docs.pytest.org/)
-   **Dependency Management**: uv (https://github.com/astral-sh/uv)
-   **Task Runner**: nox (https://nox.thea.codes/)
-   **Code Quality Management**: Ruff (https://docs.astral.sh/ruff/), Pyright (https://github.com/microsoft/pyright)
-   **Validation**: Pydantic (https://docs.pydantic.dev/)
-   **Version Control**: Git

## Essential Reference Resources

**YOU MUST** refer to the following official documentation during implementation:

-   Python Official: https://docs.python.org/3/
-   FastAPI: https://fastapi.tiangolo.com/
-   Pydantic v2: https://docs.pydantic.dev/latest/
-   pytest: https://docs.pytest.org/en/stable/
-   uv: https://github.com/astral-sh/uv#documentation
-   nox: https://nox.thea.codes/en/stable/

## Development Commands

This project uses `nox` as the task runner. Common development commands:

### Core Development Tasks

-   `nox -s lint` - Run linting with Ruff
-   `nox -s format_code` - Format code with Ruff
-   `nox -s sort` - Sort imports with Ruff
-   `nox -s typing` - Run type checking with Pyright
-   `nox -s test` - Run tests with pytest and coverage (requires 80% minimum)
-   `nox -s security` - Run security checks (bandit, pip-audit)
-   `nox -s docs` - Build documentation with MkDocs

### Composite Tasks

-   `nox -s ci` - Run all CI checks (lint, sort, format_code, typing, test, security)
-   `nox -s all_checks` - Run all quality checks including documentation

### Test-Specific Tasks

-   `nox -s test_unit` - Run unit tests only
-   `nox -s test_api` - Run API tests only
-   `nox -s test_e2e` - Run E2E tests only
-   `nox -s coverage` - Measure coverage with detailed report

### Direct Commands (when needed)

-   `uv sync` - Install/update dependencies
-   `uv run pytest` - Run tests directly
-   `uv run ruff format .` - Format code directly
-   `uv run ruff check .` - Lint code directly
-   `uv run pyright` - Type check directly

### Dependency Management (uv)

**CRITICAL**: Use `uv` for all dependency management. `pip` and `poetry` are PROHIBITED.

```bash
# Project initialization
uv init

# Add dependency
uv add <package>

# Add development dependency
uv add --dev <package>

# Install dependencies
uv sync

# Execute command in virtual environment
uv run <command>
```

## Project Architecture

### Structure

This project follows a structured Python library architecture:

```
project_root/
├── .claude/              # Claude Code specific settings
│   └── commands/         # Custom commands
├── .github/              # GitHub Actions
│   └── workflows/
├── src/                  # Application code
│   └── <library_name>/   # Main library code (dynamically named)
├── tests/                # Test code
│   ├── unit/            # Unit tests
│   ├── api/             # API tests
│   └── e2e/             # E2E tests
├── docs/                 # Documentation
├── constraints/          # Dependency constraint files generated by nox
├── .gitignore
├── CLAUDE.md            # This file
├── CLAUDE.local.md      # Local-only settings (Git excluded)
├── PROGRESS.md          # Development progress record
├── pyproject.toml       # Project configuration
├── noxfile.py           # nox task definitions
└── README.md
```

### Key Configuration Files

-   **pyproject.toml**: Project configuration with placeholders that get replaced by `setup.sh`
-   **noxfile.py**: Task automation with comprehensive quality checks
-   **mkdocs.yml**: Documentation configuration

### Development Workflow

1. The project uses template placeholders ({{PROJECT_NAME}}, {{LIBRARY_NAME}}, etc.) that are replaced during setup
2. Library name is configured in `src/{library_name}/` and must be valid Python identifier
3. Tests require 80% minimum coverage to pass
4. All code quality tools are configured to work together via nox

### Setup Process

-   Run `./setup.sh` to initialize the project with actual values
-   The script creates the library directory structure and main.py entry point
-   It handles license generation and file template replacement

## Development Workflow - 4-Phase Approach

### CRITICAL: All new features and bug fixes MUST follow these 4 phases

#### Phase 1: Explore - Information Gathering

**DO NOT** modify code in this phase.

Activities:

1. Read related files (`src/`, `tests/`, `pyproject.toml`)
2. Understand existing implementation patterns
3. Check dependencies
4. Identify scope of impact

Completion confirmation:

```
"Exploration phase completed. Confirmed the following:
- Related files: [file list]
- Existing patterns: [pattern overview]
- Impact scope: [affected areas]"
```

#### Phase 2: Plan - Implementation Design

**YOU MUST** create a plan in the following format:

```markdown
## Implementation Plan: [Feature Name/Bug Fix Name]

### 1. Overview

[What to implement/fix]

### 2. File Changes

-   New files:
    -   `path/to/new/file.py` - [purpose]
-   Modifications:
    -   `path/to/existing/file.py` - [change details]

### 3. Test Plan (Implementation Order)

1. E2E Tests (Most abstract):
    - `test_user_complete_journey` - Complete user flow from registration to deletion
2. API Tests (Middle layer):
    - `test_create_user_endpoint` - User creation API
    - `test_get_user_endpoint` - User retrieval API
3. Unit Tests (Most concrete):
    - `test_user_model_validation` - Model validation
    - `test_user_service_create` - Service layer logic

### 4. Implementation Order

1. Create test cases (E2E → API → Unit)
2. Implementation (Unit → API → E2E)
3. Verify all tests pass
4. Refactoring
5. Documentation update
```

#### Phase 3: Implement - Execute TDD

**NEVER** start implementation without writing tests first.

#### Phase 4: Commit - Record Changes

**YOU MUST** commit only after all checks are completed.

## Strict Test-Driven Development (TDD) Implementation

### CRITICAL: Test Creation and Implementation Order

**Test Creation Order** (Abstract → Concrete):

1. **E2E Tests** - Define system-wide behavior
2. **API Tests** - Define endpoint-level specifications
3. **Unit Tests** - Define detailed specifications for individual components

**Implementation Order** (Concrete → Abstract):

1. **Unit Implementation** - Models, services, utilities
2. **API Implementation** - Endpoints, middleware
3. **Integration** - Combine everything to pass E2E tests

### Test Cheating Prevention Rules

**CRITICAL - The following are ABSOLUTELY PROHIBITED**:

```python
# ❌ Prohibited Example 1: Hardcoding just to pass tests
def calculate_total(items: list[dict[str, float]]) -> float:
    # NEVER DO THIS
    if items == [{"price": 100}, {"price": 200}]:
        return 300  # Hardcoded expected value from test case

# ❌ Prohibited Example 2: Special handling only for tests
def process_order(order_id: str) -> dict[str, str]:
    # NEVER DO THIS
    if order_id == "test_order_123":  # Special treatment for test data
        return {"status": "success"}

# ❌ Prohibited Example 3: Cheating with log output
def validate_input(data: dict[str, str]) -> bool:
    # NEVER DO THIS
    print("Validation passed!")  # Just log output without actual validation
    return True
```

**✅ Correct Implementation Examples**:

```python
# Correct implementation: Properly implement logic
def calculate_total(items: list[dict[str, float]]) -> float:
    return sum(item.get("price", 0) for item in items)

# Temporary debug during development (remove after completion)
def complex_calculation(data: dict[str, str]) -> dict[str, str]:
    print(f"DEBUG: Input data: {data}")  # Temporary debug
    result = perform_calculation(data)
    print(f"DEBUG: Result: {result}")    # Temporary debug
    # TODO: Remove above print statements after debugging completion
    return result
```

## Code Quality Standards

### CRITICAL: Ruff and Pyright Enforcement

**YOU MUST** run Ruff and Pyright checks continuously during coding:\*\*

-   Run `nox -s lint` after every code modification
-   Run `nox -s typing` after every code modification
-   **NEVER** disable Ruff or Pyright warnings with `# type: ignore` or `# noqa`
-   **NEVER** use temporary suppression comments
-   Fix all warnings and errors immediately

### Modern Python Type Hinting (Python 3.12+)

**CRITICAL: Use modern Python 3.12+ type syntax:**

```python
# ✅ CORRECT - Modern Python 3.12+ syntax
from typing import TypeVar, Generic, Callable, Any
from collections.abc import Sequence, Mapping
from pathlib import Path

# Use built-in types, not typing equivalents
def process_items(items: list[dict[str, str]]) -> dict[str, list[str]]:
    """Process items with modern type hints."""
    pass

# Use union syntax, not Optional
def get_user(user_id: int) -> User | None:
    """Get user by ID."""
    pass

# Use generic syntax
T = TypeVar("T")

class Repository(Generic[T]):
    """Generic repository."""

    def save(self, entity: T) -> T:
        """Save entity."""
        pass

    def find_by_id(self, id: int) -> T | None:
        """Find entity by ID."""
        pass

# Use precise types, avoid Any
def process_config(config: dict[str, str | int | bool]) -> None:
    """Process configuration with specific types."""
    pass

# ❌ INCORRECT - Old Python syntax
from typing import Optional, List, Dict, Union

def old_style(items: List[Dict[str, str]]) -> Optional[Dict[str, List[str]]]:
    pass

def uses_any(data: Any) -> Any:  # Avoid Any unless absolutely necessary
    pass
```

### Type Checking with Pyright

**YOU MUST** ensure all code passes Pyright's `strict` mode without errors:

```python
# pyrightconfig.json configuration
{
    "include": ["src", "tests"],
    "exclude": ["**/__pycache__"],
    "typeCheckingMode": "strict",
    "pythonVersion": "3.13",
    "reportUnknownMemberType": false,
    "reportUnknownArgumentType": false
}
```

Type annotation examples:

```python
from typing import TypeVar, Generic
from pydantic import BaseModel, Field, ConfigDict

T = TypeVar("T")

class PaginatedResponse(BaseModel, Generic[T]):
    """Pagination response with proper typing."""
    model_config = ConfigDict(from_attributes=True)

    items: list[T]
    total: int
    page: int = Field(..., ge=1)
    per_page: int = Field(..., ge=1, le=100)

    @property
    def total_pages(self) -> int:
        """Calculate total pages."""
        return (self.total + self.per_page - 1) // self.per_page
```

### Formatting and Linting with Ruff

Configuration in `pyproject.toml`:

```toml
[tool.ruff]
target-version = "py312"
line-length = 88
exclude = [
    ".bzr", ".direnv", ".eggs", ".git", ".git-rewrite", ".hg",
    ".ipynb_checkpoints", ".mypy_cache", ".nox", ".pants.d",
    ".pyenv", ".pytest_cache", ".pytype", ".ruff_cache", ".svn",
    ".tox", ".venv", ".vscode", "__pypackages__", "_build",
    "buck-out", "build", "dist", "node_modules", "site-packages", "venv"
]

[tool.ruff.lint]
select = ["ALL"]
ignore = [
    "COM812", "COM819",
    "D100", "D203", "D213", "D300",
    "E111", "E114", "E117",
    "ISC001", "ISC002",
    "Q000", "Q001", "Q002", "Q003",
    "W191",
    "T", "D"
]
fixable = ["ALL"]
unfixable = []
dummy-variable-rgx = "^(_+|(_+[a-zA-Z0-9_]*[a-zA-Z0-9]+?))$"

[tool.ruff.lint.per-file-ignores]
"tests/**/*.py" = ["S101"]

[tool.ruff.format]
quote-style = "double"
indent-style = "space"
skip-magic-trailing-comma = false
line-ending = "auto"
```

## Testing Standards

### Testing Notes

-   Tests are automatically skipped if no Python files exist in src directory
-   Coverage threshold is set to 80% minimum
-   Test configuration includes markers for slow and integration tests
-   Use proper type hints in all test code

### TDD Implementation Examples

```python
# tests/e2e/test_product_management.py
import pytest
from fastapi.testclient import TestClient

class TestProductManagement:
    """Complete workflow test for product management."""

    def test_complete_product_lifecycle(
        self,
        client: TestClient,
        auth_headers: dict[str, str]
    ) -> None:
        """Complete lifecycle from product creation to deletion."""
        # 1. Create product
        create_response = client.post(
            "/api/v1/products",
            json={
                "name": "Test Product",
                "price": 1000,
                "stock": 100
            },
            headers=auth_headers
        )
        assert create_response.status_code == 201
        product_id: str = create_response.json()["id"]

        # 2. Get product information
        get_response = client.get(f"/api/v1/products/{product_id}")
        assert get_response.status_code == 200
        assert get_response.json()["name"] == "Test Product"

        # 3. Update stock
        update_response = client.patch(
            f"/api/v1/products/{product_id}",
            json={"stock": 50},
            headers=auth_headers
        )
        assert update_response.status_code == 200

        # 4. Delete product
        delete_response = client.delete(
            f"/api/v1/products/{product_id}",
            headers=auth_headers
        )
        assert delete_response.status_code == 204
```

## Git Operation Rules

### Strict Application of Conventional Commits

**NEVER** use non-standard commit messages.

Format:

```
<type>(<scope>): <subject>

<body>

<footer>
```

Specific examples:

```bash
# Feature addition
feat(auth): implement JWT authentication feature

- Issue and refresh token generation
- Token validation middleware addition
- Authentication error handling implementation

Closes #123

# Bug fix
fix(api): fix foreign key constraint error on user deletion

Modified to delete related profile information first

# Test addition
test(product): implement E2E/API/unit tests for product management

- E2E test: Complete product lifecycle
- API test: Validation of each endpoint
- Unit test: Model and service logic
```

## Error Handling

### Custom Exception Usage with Proper Types

```python
# src/core/exceptions.py
from fastapi import HTTPException

class AppException(HTTPException):
    """Application base exception."""

    def __init__(
        self,
        status_code: int,
        detail: str,
        headers: dict[str, str] | None = None
    ) -> None:
        super().__init__(status_code=status_code, detail=detail, headers=headers)

class ValidationError(AppException):
    """Validation error."""

    def __init__(self, detail: str) -> None:
        super().__init__(status_code=400, detail=detail)

class NotFoundError(AppException):
    """Resource not found error."""

    def __init__(self, resource: str) -> None:
        super().__init__(status_code=404, detail=f"{resource} not found")

class ConflictError(AppException):
    """Conflict error."""

    def __init__(self, detail: str) -> None:
        super().__init__(status_code=409, detail=detail)

# Usage example (no hardcoding)
def get_user(user_id: int) -> User:
    user = repository.find_by_id(user_id)
    if not user:
        # ❌ NEVER: return {"error": "User not found"}  # Hardcoded error
        # ✅ CORRECT:
        raise NotFoundError("User")
    return user
```

## Security Rules

### Environment Variables and Secret Management

```python
# src/config.py
from pydantic_settings import BaseSettings, SettingsConfigDict

class Settings(BaseSettings):
    """Application settings."""
    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding="utf-8",
        case_sensitive=False
    )

    # API settings
    api_key: str
    secret_key: str

    # Database settings
    database_url: str

    # Optional settings
    debug: bool = False
    cors_origins: list[str] = ["http://localhost:3000"]

    # Test settings
    testing: bool = False

    @property
    def is_production(self) -> bool:
        """Check if production environment."""
        return not (self.debug or self.testing)

settings = Settings()
```

**NEVER**:

-   Hardcoded credentials
-   Commit `.env` files
-   Output sensitive information to logs
-   Special authentication bypass for tests

## Progress Management and Documentation

### PROGRESS.md Recording Format

**YOU MUST** record in the following format at the end of each work session:

```markdown
## 2024-01-20 - Product Management Feature Implementation

### Completed Phases

-   [x] Explore: Investigated existing model structure and API patterns
-   [x] Plan: Created test plan in E2E→API→Unit order
-   [x] Implement: Implemented features with TDD (tests: E2E→API→Unit, implementation: Unit→API→E2E)
-   [x] Commit: Committed with feat(product)

### Implementation Details

#### Test Creation Order

1. `tests/e2e/test_product_management.py` - Complete product lifecycle
2. `tests/api/test_products_api.py` - Individual endpoints
3. `tests/unit/test_product_model.py` - Model validation
4. `tests/unit/test_product_service.py` - Business logic

#### Implementation Order

1. `src/models/product.py` - Pydantic model
2. `src/services/product_service.py` - Business logic
3. `src/api/v1/products.py` - API endpoints
4. Integration and all tests pass

#### Code Quality Verification

-   [x] All Ruff checks passed: `nox -s lint`
-   [x] All Pyright checks passed: `nox -s typing`
-   [x] All tests passed: `nox -s test`
-   [x] Coverage above 80%: 99%
-   [x] No debug logs remain: `nox -s clean_debug`

### Debug Log Removal Confirmation

-   [x] Removed all temporary print statements
-   [x] Removed debug comments
-   [x] Resolved TODO/FIXME

### Next Tasks

-   [ ] Implement product search functionality
-   [ ] Add stock alert functionality
-   [ ] Create performance tests
```

## Quality Assurance Checklist

### Pre-commit Mandatory Checks

```bash
# Run all checks at once
nox

# Stepwise test execution (recommended)
nox -s test_unit     # First unit tests
nox -s test_api      # Then API tests
nox -s test_e2e      # Finally E2E tests

# Quality checks - RUN AFTER EVERY CODE CHANGE
nox -s lint          # Ruff linting - MANDATORY
nox -s format_code   # Ruff formatting - MANDATORY
nox -s typing        # Pyright type checking - MANDATORY
nox -s coverage      # Coverage (80%+ required)
nox -s clean_debug   # Debug code detection
```

### Pre-Pull Request Checklist

-   [ ] All nox sessions pass
-   [ ] Test coverage is 80%+
-   [ ] Debug logs removed
-   [ ] PROGRESS.md updated
-   [ ] 3-layer tests (E2E/API/Unit) added for new features
-   [ ] All type hints are modern Python 3.12+ syntax
-   [ ] No Ruff or Pyright suppressions used
-   [ ] Breaking changes documented if any

## Development Iron Rules

1. **Test First, Always** - Write tests in E2E→API→Unit order
2. **Implementation: Concrete to Abstract** - Implement in Unit→API→E2E order
3. **No Cheating** - Don't pass tests with hardcoding or logs
4. **Debug Logs are Temporary** - Must remove after use
5. **No Implementation Without Planning** - Always execute 4 phases
6. **Quality Gate Compliance** - Pass all nox checks before commit
7. **Modern Type Hints** - Use Python 3.12+ syntax, avoid Any, no typing imports for built-ins
8. **Never Suppress Warnings** - Fix all Ruff and Pyright issues immediately
9. **Continuous Quality Checks** - Run lint and typing after every modification
10. **Progress Visualization** - Always update PROGRESS.md

## Common Commands Reference

```bash
# Development environment
uv run uvicorn src.myapp.main:app --reload --host 0.0.0.0 --port 8000

# Test execution (recommended order)
nox -s test_unit                              # Unit tests first
nox -s test_api                               # API tests
nox -s test_e2e                               # E2E tests
nox -s test                                   # All tests at once

# Quality checks - CONTINUOUS EXECUTION REQUIRED
nox -s lint                                   # After every code change
nox -s typing                                 # After every code change
nox -s format_code                            # Code formatting
nox -s coverage                               # Coverage check

# Git operations
git add -A && git commit                      # Interactive commit
git push origin feature/123-new-feature       # Branch push

# Dependencies
uv add fastapi                                # Add production dependency
uv add --dev pytest-mock                      # Add dev dependency
uv sync                                       # Sync dependencies
```

## Troubleshooting

### Common Problems and Solutions

#### Ruff/Pyright Suppression Temptation

```python
# ❌ NEVER DO THIS - Suppressing warnings
def problematic_function(data):  # type: ignore
    pass

def another_function(items):  # noqa: ANN001
    pass

# ✅ CORRECT - Fix the issue
def fixed_function(data: dict[str, str]) -> None:
    pass

def another_fixed_function(items: list[str]) -> list[str]:
    return items
```

#### Type Hint Modernization

```python
# ❌ OLD STYLE - Don't use these
from typing import Optional, List, Dict, Union

def old_function(items: List[Dict[str, str]]) -> Optional[str]:
    pass

# ✅ MODERN STYLE - Use these
def modern_function(items: list[dict[str, str]]) -> str | None:
    pass
```

#### Continuous Quality Check Workflow

```bash
# After making any code change:
nox -s lint      # Check immediately
nox -s typing    # Check immediately

# If errors found, fix them before continuing
# NEVER proceed with suppression comments
```

## Test Helpers

### Pexpect Debug Helper

When testing CLI applications with pexpect, use the `tests/helpers/pexpect_debug.py` helper for better debugging:

```python
from tests.helpers.pexpect_debug import run_cli_with_debug, spawn_cli_with_debug

# Simple command execution with debug output
def test_cli_command(clean_env: dict[str, str]) -> None:
    output, exitstatus = run_cli_with_debug(
        f"{sys.executable} -u -m clean_interfaces.main --help",
        env=clean_env,
        timeout=10,
        debug=True,  # Enable debug output
    )
    assert exitstatus == 0

# Interactive session for complex testing
def test_interactive_cli(clean_env: dict[str, str]) -> None:
    child = spawn_cli_with_debug(
        f"{sys.executable} -u -m clean_interfaces.main",
        env=clean_env,
        timeout=30,
        debug=True,
    )
    child.expect("prompt>")
    child.sendline("command")
    child.expect("response")
```

#### Debug Mode

-   Set `debug=True` or environment variable `PYTEST_DEBUG=1` to enable debug output
-   Debug output includes:
    -   Command being executed
    -   Environment variables
    -   Exit status
    -   Full output with length
    -   Timeout information

#### When to Use

-   **Always use for E2E tests**: Provides better error messages than raw pexpect
-   **Debugging test failures**: Enable debug mode to see what's happening
-   **CI/CD debugging**: Set `PYTEST_DEBUG=1` in CI to get detailed logs

#### Example Debug Output

```
[DEBUG] Running command: /workspace/.venv/bin/python3 -u -m clean_interfaces.main
[DEBUG] Environment: {'PATH': '...', 'LOG_LEVEL': 'ERROR', ...}
[DEBUG] Timeout: 10s
--------------------------------------------------------------------------------
[DEBUG] Exit status: 0
[DEBUG] Output length: 584 chars
[DEBUG] Output:
--------------------------------------------------------------------------------
Welcome to Clean Interfaces!
Type --help for more information
--------------------------------------------------------------------------------
```

---

**Remember**:

-   Tests: Abstract to Concrete (E2E → API → Unit)
-   Implementation: Concrete to Abstract (Unit → API → E2E)
-   Quality checks after every single code modification
-   Modern Python 3.13+ type syntax always
-   Never suppress Ruff or Pyright warnings
-   Use pexpect_debug helper for all E2E/CLI tests
-   This document is living documentation. Evolve it as the project grows.
